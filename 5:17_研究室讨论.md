## 5/17 研究室讨论



* 之前下平先生说我和研究室的联系不够紧密，交流太少，而且自己现在研究水平比较差，所以我希望更多的在这个频道发一些关于我研究方面的东西，以及更细节的一些东西，让各位先生知道我在做什么，并且在我研究走偏的时候随时纠正我。同时我也会提出一些自己疑问和需要帮助的点，但如果您时间有限的话也可以不回答我。

  * 之前下平先生说我目前的知识面非常有限，希望我能拓展自己的知识面。所以我会在我目前正在进行的研究上，多去看看其余相关领域的论文和研究室的论文以此得到一些启发，然后扩展我的研究。
  * 我看了oyama san和yamagiwa san的频道后，我也准备用dropbox记录自己的研究，用github记录总结自己看过的论文（有的泛读，有的精读），这学期修了7门课，所以可能关于研究和看论文在某些时间段会更新缓慢。

  * 关于目前的研究内容：
    * 现在：希望能将Knowledge Graph作为resource和利用图结构去完成一些NLP的任务（Question Answering等等），目前还会继续去跟进研究。
    * 过去一周在下平先生的建议以及看了一些论文和Survey后，我发现研究KGs本身也很有趣， Knowledge Graph Embedding和Knowledge Graph Completion，还有一些其余相关的研究（可能我这里描述的也比较宽泛，没涉及到细节，我之后也会继续跟进到一些更具体的部分）
      * 这一部分的内容也和研究室过去或者现在研究的内容有一定的关联，不像之前那样完全偏向了另一个方向。
      * KGE, KGC和Word Embedding以及Sentence Embedding是有一定的联系的，也许这里面有些有趣的东西可以相互影响。
      * 关于KGE, 一个好的KGE，是可以让KG的作用变的更加强大的，可以更好的被利用在QA,NLG等NLP的任务上，所以关于这个的研究不仅仅在其本身有意义，还可以迁移到其余的领域（QA）。不过我发现关于这一方向的研究从2014年就开始了，我不确定这里面是否还有很多探索的空间？



* 先日、下平先生から「コミュニケーションが少なすぎる」という話がありました。 そして、私自身の研究のレベルが今ひとつ低いこと。 ですから、このチャンネルでは、私の研究の一面や、より細かいことをもっと書いて、先生方が私の研究を知って、私の研究がレールから外れたときに訂正できるようにしたいと思います。 また、質問や困っている点などを聞いていきますが、時間が限られている場合は答えてくれなくても構いません。
  * 下平先生は、「今の私の知識はとても浅いので、知識と論文の範囲を増やしてほしい」とおっしゃっていました。 そこで、現在行っている研究をベースに、他の関連分野や研究所の論文を見て、ヒントを得て、研究の幅を広げていきたいと考えています。
  * 大山さんと山際さんのチャンネルを見て、dropboxで研究の記録、githubで読んだ論文のまとめ（ざっくりしたもの、詳細なもの）を記録しようと思っていますが、今学期は7科目履修しているので、時期によっては研究や論文の更新が遅くなるかもしれませんね。
  * 現在の研究内容について：
    * 現在：「Knowledge」を「resource」として、「graph structure」をいくつかのNLPタスク（Question Answeringなど）に利用できればと考えており、今後もフォローアップを続けていきます。
    * この一週間でいくつかの論文やSurveysを読み、下平先生のアドバイスに従って、KGそのもの、Knowledge Graph EmbeddingやKnowledge Graph Completion、その他関連する研究をすると面白いと思いました（たぶんここではもっと大まかに記述していて詳細には触れていないので、より具体的な部分は後でフォローアップします）。
      * この部分は、研究室との関連もあります、以前の研究は、まったく違う方向に進んでいた。
      * KGE、KGCとWord Embedding、Sentence Embeddingは何らかの関係があるので、もしかしたらここに何か面白いものがあって、お互いに影響し合えるかもしれませんね。
      * KGEに関しては、良いKGEはKGの役割をより強力にし、QAやNLGなどのNLPタスクにもっと活用できるものであり、これに関する研究はそれ自体だけでなく、他のドメイン（QA）に転用することも可能である。
      * KGE: この方向性の研究は2014年から行われていることがわかりますが、ここはあまり開拓の余地がないのでしょうか



これは、上記の英語部分です。上記には不明瞭な点があるかもしれません（日本語はあまり得意ではありません）。



* Earlier Shimodaira sensei said that I don't have enough connection with my research office and too little communication, and I realize that my research level is rather poor now, so I would like to post more things about my research on this channel, and some more details about my research, so that you can know what I am doing and correct me anytime when my research goes off track. Also, I will raise some questions of my own and points where I need help, but you don't need to answer me if your time is limited.
  * Shimodaira sensei said earlier that my current knowledge is very limited and hoped that I can expand my knowledge and scope of reading papers. Therefore, I will expand my research by reading more papers in other related fields and the papers in our lab, based on the research I am currently doing.
  * After I browsed 大山さん and 山際さん's channel, I'm also going to use dropbox to record my research and GitHub to record and summarize the papers I've read (some general reading and some detailed reading). I'm taking 7 courses this semester, so I might be slow to update about research and reading papers at some time.
  * Research Part:
    * Now: I want to use Knowledge Graph as resource and use the graph structure to accomplish some NLP tasks (Question Answering, etc.), and I will continue to follow up on the research.
    * In the last week under Shimodaira sensei's advice and after reading some papers and Surveys, I found it interesting about KGs itself, Knowledge Graph Embedding, and Knowledge Graph Completion, as well as some of the rest of the relevant research (perhaps my description here is also rather broad and does not cover the details, and I will continue to follow up to some more specific parts afterward)
      * This section is also somewhat related to what the research lab has been or is currently researching, unlike before my research part was in a completely different direction.
      * 「KGE, KGC」, and 「Word Embedding, Sentence Embedding」are somewhat related, and perhaps there are some interesting things in there that can influence each other.
      * Regarding KGE, a good KGE is one that makes KG more powerful and can be better utilized for NLP tasks such as QA, NLG, etc. So research on this is not only relevant in its own right, but can also be migrated to the rest of the domain (QA). But I found that research on this direction has been going on since 2014, I'm not sure if there is much research space for exploration here?